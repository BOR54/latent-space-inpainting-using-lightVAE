Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
/home/bmutembei36/.conda/envs/lightvae/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/home/bmutembei36/.conda/envs/lightvae/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name      | Type              | Params | Mode  | FLOPs
----------------------------------------------------------------
0 | encoder   | LiteVAE_Encoder   | 6.6 M  | train | 0    
1 | decoder   | LiteVAE_Decoder   | 53.4 M | train | 0    
2 | loss      | LiteVAEAuthorLoss | 0      | train | 0    
3 | quantizer | Module            | 0      | train | 0    
----------------------------------------------------------------
60.0 M    Trainable params
0         Non-trainable params
60.0 M    Total params
239.897   Total estimated model params size (MB)
740       Modules in train mode
0         Modules in eval mode
0         Total Flops
SLURM auto-requeueing enabled. Setting signal handlers.
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** JOB 29396865 ON c1042 CANCELLED AT 2026-02-10T16:18:23 ***
slurmstepd: error: *** STEP 29396865.0 ON c1042 CANCELLED AT 2026-02-10T16:18:23 ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
